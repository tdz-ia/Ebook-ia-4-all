{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"dataset\"\n",
    "file   =\"validation\"\n",
    "out=\"TFrecords_DS\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = [160, 160]\n",
    "class_names=[\"cats\",'dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=os.path.join(out,file )\n",
    "\n",
    "PATH = os.path.join(dataset)\n",
    "PATH = os.path.join(PATH, file+\"/*/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "1000\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.list_files(PATH)\n",
    "\n",
    "totalims=tf.data.experimental.cardinality(list_ds).numpy()\n",
    "print(type(list_ds))\n",
    "print(len(list_ds))\n",
    "lotes= math.ceil(totalims/BATCH_SIZE)\n",
    "print(lotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename):\n",
    "    parts = tf.strings.split(filename, os.sep)\n",
    "    label = parts[-2]\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, IMG_SIZE)      \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 imagenes en 32 lotes de 32\n"
     ]
    }
   ],
   "source": [
    "DataSet = list_ds.map(parse_image)\n",
    "DataSet = DataSet.shuffle(BATCH_SIZE*4)\n",
    "DataSet = DataSet.repeat()\n",
    "DataSet = DataSet.batch(BATCH_SIZE)\n",
    "\n",
    "#totalims=tf.data.experimental.cardinality(DataSet).numpy()\n",
    "\n",
    "3\n",
    "print(\"{} imagenes en {} lotes de {}\".format(totalims, lotes, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "for images, labels in DataSet.take(1):\n",
    "    print(images.shape)\n",
    "        \n",
    "  \n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        im= images[i]/255\n",
    "        plt.imshow(im)\n",
    "        name=labels[i].numpy().decode('utf-8')\n",
    "        clase=class_names.index(labels[i])\n",
    "        plt.title(name)\n",
    "        plt.axis(\"off\")        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar=widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=lotes,\n",
    "    step=0.1,\n",
    "    description='Loading:',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defeniciones para la serializacion de datos\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    # Create a dictionary with features that may be relevant.\n",
    "\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "    #print(\"image_shape\",image_shape )\n",
    "    \n",
    "    feature = {\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0969a9d35f44d5be7c8ba60fc6c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Loading:', max=32.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: Con 1024 imagenes, se crearon 32 lotes, con 32 imagenes cada uno  \n",
      "info: dir:  TFrecords_DS/validation\n"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "for x, batch in enumerate(DataSet.take(lotes)):\n",
    "    images, labels =batch          \n",
    "    \n",
    "    paso= (x+1)*(len(images))\n",
    "    bar.value=x\n",
    "    \n",
    "    output_filename = '%s-%.5d-of-%.5d' % (file, z, paso)\n",
    "    output_file = os.path.join(output_directory, output_filename+\".tfrecords\")\n",
    "      \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    \n",
    "   # print(\"imagen {} a {} de {}, tam lote:{}, #lote:{}\".format(z, paso,totalims ,len(images),x  ) )\n",
    "    #print(\"tam lote:{},  numero de lote :{}\".format( )) \n",
    "    #print(\"output_file \",output_file) \n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_file) as writer:       \n",
    "        for i in range(len(images)): \n",
    "            z+=1          \n",
    "            img=img_to_array(images[i])\n",
    "            image_raw= tf.io.encode_jpeg(img)\n",
    "            #image_raw=img\n",
    "            label=class_names.index(labels[i])\n",
    "            tf_example = image_example(image_raw, label)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        writer.close()\n",
    "        \n",
    "print(\"info: Con {} imagenes, se crearon {} lotes, con {} imagenes cada uno  \".format( z, lotes, BATCH_SIZE))  \n",
    "print(\"info: dir: \",output_directory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
